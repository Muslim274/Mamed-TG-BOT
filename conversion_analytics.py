#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø: –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π GetCourse –ø–ª–∞—Ç–µ–∂–µ–π
–í–µ—Ä—Å–∏—è 4.7 - –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è
GetCourse –ø–ª–∞—Ç–µ–∂–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ –¥–∞—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∞–¥–º–∏–Ω–æ–º (Sale.created_at)
"""

import os
import sys
import logging
import asyncio
import re
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import subprocess
import pytz
import argparse

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database.connection import AsyncSessionLocal, init_db
from app.database.crud import UserCRUD
from app.database.models import User, OnboardingStage
from app.services.google_sheets import GoogleSheetsService
from app.config import settings
from sqlalchemy import select, func, and_

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/telegram-referral-bot/conversion_analytics_final.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

BOT_PATH = "/root/telegram-referral-bot"
LOG_PATTERN = r'(\d{4}-\d{2}-\d{2}) (\d{2}:\d{2}:\d{2}).*?User (\d+).*?/start'
MOSCOW_TZ = pytz.timezone('Europe/Moscow')
BACKUP_FILE = '/root/telegram-referral-bot/data_backup.json'

REQUIRED_STAGES = [
    OnboardingStage.NEW_USER,
    OnboardingStage.INTRO_SHOWN, 
    OnboardingStage.WAIT_PAYMENT,
    OnboardingStage.PAYMENT_OK,
    "DAILY_PAYMENTS"
]

STAGE_NAMES = {
    OnboardingStage.NEW_USER: "–ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏",
    OnboardingStage.INTRO_SHOWN: "–ü—Ä–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –≤–∏–¥–µ–æ (–Ω–æ –µ—â–µ –Ω–µ –∫ –æ–ø–ª–∞—Ç–µ)",
    OnboardingStage.WAIT_PAYMENT: "–û–∂–∏–¥–∞—é—Ç –æ–ø–ª–∞—Ç—É", 
    OnboardingStage.PAYMENT_OK: "–û–ø–ª–∞—Ç–∏–ª–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è+–æ–ø–ª–∞—Ç–∞ –≤ 1 –¥–µ–Ω—å)",
    "DAILY_PAYMENTS": "–í—Å–µ–≥–æ –æ–ø–ª–∞—Ç –∑–∞ –¥–µ–Ω—å (–ø–æ —Ñ–∞–∫—Ç—É)"
}

class ConversionAnalyticsFinal:
    """–§–ò–ù–ê–õ–¨–ù–ê–Ø –≤–µ—Ä—Å–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Å–∏–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ–¥—Å—á–µ—Ç–æ–º –æ–ø–ª–∞—Ç"""
    
    def __init__(self):
        self.sheets_service = GoogleSheetsService()
        self.worksheet = None
        self.last_update_date = None
        self.backup_data = {}
        
    async def init(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Sheets"""
        try:
            await init_db()
            logger.info("‚úÖ Database initialized")
            
            success = await self.sheets_service.init()
            if not success:
                raise Exception("Failed to initialize Google Sheets")
            
            sheet_name = "–ö–æ–Ω–≤–µ—Ä—Å–∏–∏ –ø–æ –¥–Ω—è–º"
            
            try:
                self.worksheet = self.sheets_service.spreadsheet.worksheet(sheet_name)
                logger.info(f"‚úÖ Found existing '{sheet_name}' worksheet")
                
                headers = self.worksheet.row_values(1)
                expected_headers = ["–î–∞—Ç–∞", "–í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"] + [STAGE_NAMES[stage] for stage in REQUIRED_STAGES]
                
                if not headers or headers != expected_headers:
                    logger.info("üîÑ Updating headers...")
                    self.worksheet.update(range_name='A1:G1', values=[expected_headers])
                    time.sleep(2)
                    
            except:
                logger.info(f"üîÑ Creating new '{sheet_name}' worksheet")
                self.worksheet = self.sheets_service.spreadsheet.add_worksheet(
                    title=sheet_name, 
                    rows=1000, 
                    cols=10
                )
                
                headers = ["–î–∞—Ç–∞", "–í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"] + [STAGE_NAMES[stage] for stage in REQUIRED_STAGES]
                self.worksheet.update(range_name='A1:G1', values=[headers])
                time.sleep(2)
                logger.info("‚úÖ Headers added to new worksheet")
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            await self.create_backup()
            
            self.last_update_date = await self._get_last_update_date()
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing: {e}")
            return False
    
    async def create_backup(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            all_values = self.worksheet.get_all_values()
            
            backup_data = {
                'timestamp': datetime.now(MOSCOW_TZ).isoformat(),
                'data': all_values,
                'total_rows': len(all_values)
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            with open(BACKUP_FILE, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç–∏
            self.backup_data = backup_data
            
            logger.info(f"üíæ Backup created: {len(all_values)} rows saved to {BACKUP_FILE}")
            
        except Exception as e:
            logger.error(f"‚ùå Error creating backup: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –µ—Å–ª–∏ –±—ç–∫–∞–ø –Ω–µ —É–¥–∞–ª—Å—è
    
    async def restore_from_backup(self):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            if os.path.exists(BACKUP_FILE):
                with open(BACKUP_FILE, 'r', encoding='utf-8') as f:
                    backup_data = json.load(f)
                
                if backup_data.get('data'):
                    # –û—á–∏—â–∞–µ–º –ª–∏—Å—Ç
                    self.worksheet.clear()
                    time.sleep(1)
                    
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    if backup_data['data']:
                        self.worksheet.update('A1', backup_data['data'])
                        logger.info(f"üîÑ Restored {len(backup_data['data'])} rows from backup")
                        return True
            
            logger.error("‚ùå No valid backup found")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error restoring backup: {e}")
            return False
    
    async def _get_last_update_date(self) -> Optional[datetime]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        try:
            all_values = self.worksheet.get_all_values()
            if len(all_values) <= 1:
                return None
            
            last_row = all_values[-1]
            date_str = last_row[0] if last_row else ''
            
            if not date_str:
                return None
            
            try:
                return datetime.strptime(date_str, '%d.%m.%Y')
            except:
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error getting last update date: {e}")
            return None
    
    async def get_users_from_logs_by_date(self, start_date: Optional[datetime] = None) -> Dict[str, set]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ –ª–æ–≥–æ–≤"""
        users_by_date = defaultdict(set)
        
        try:
            cmd = [
                "find", BOT_PATH, 
                "-type", "f", 
                "(", "-name", "*.log", "-o", "-name", "*.txt", ")"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"‚ùå Find command failed: {result.stderr}")
                return {}
                
            log_files = [f for f in result.stdout.strip().split('\n') if f.strip()]
            logger.info(f"üìÇ Found {len(log_files)} log files")
            
            processed_files = 0
            for log_file in log_files:
                if not log_file:
                    continue
                    
                try:
                    grep_cmd = ["grep", "/start", log_file]
                    grep_result = subprocess.run(grep_cmd, capture_output=True, text=True)
                    
                    if grep_result.stdout:
                        lines = grep_result.stdout.strip().split('\n')
                        
                        for line in lines:
                            if not line.strip():
                                continue
                                
                            match = re.search(LOG_PATTERN, line)
                            if match:
                                date_str = match.group(1)
                                user_id = int(match.group(3))
                                
                                if start_date:
                                    try:
                                        log_date = datetime.strptime(date_str, '%Y-%m-%d')
                                        if log_date <= start_date:
                                            continue
                                    except ValueError:
                                        logger.warning(f"‚ö†Ô∏è Invalid date in log: {date_str}")
                                        continue
                                
                                users_by_date[date_str].add(user_id)
                    
                    processed_files += 1
                    if processed_files % 10 == 0:
                        logger.info(f"üìÇ Processed {processed_files}/{len(log_files)} files")
                                
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error processing file {log_file}: {e}")
                    continue
            
            total_events = sum(len(users) for users in users_by_date.values())
            logger.info(f"üìä Found {total_events} /start events across {len(users_by_date)} days")
            
            return dict(users_by_date)
            
        except Exception as e:
            logger.error(f"‚ùå Error getting users from logs: {e}", exc_info=True)
            return {}
    
    async def get_users_by_stages_for_dates(self, date_list: List[str]) -> Dict[str, Dict[str, int]]:
        """
        –ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–ü–ò–°–ê–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ–¥—Å—á–µ—Ç–æ–º payment_completed
        """
        result = {}
        
        async with AsyncSessionLocal() as session:
            for date_str in date_list:
                logger.info(f"üìÑ Processing date: {date_str}")
                
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    date_start = date_obj.replace(hour=0, minute=0, second=0, microsecond=0)
                    date_end = date_start + timedelta(days=1)
                    
                    stage_counts = {
                        OnboardingStage.NEW_USER: 0,
                        OnboardingStage.INTRO_SHOWN: 0,
                        OnboardingStage.WAIT_PAYMENT: 0,
                        OnboardingStage.PAYMENT_OK: 0,
                        "DAILY_PAYMENTS": 0
                    }
                    
                    # 1. INTRO_SHOWN: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –¢–û–ß–ù–û –≤ —Å—Ç–∞–¥–∏–∏ INTRO_SHOWN
                    try:
                        intro_result = await session.execute(
                            select(func.count(User.id))
                            .where(
                                and_(
                                    User.created_at >= date_start,
                                    User.created_at < date_end,
                                    User.onboarding_stage == OnboardingStage.INTRO_SHOWN
                                )
                            )
                        )
                        stage_counts[OnboardingStage.INTRO_SHOWN] = intro_result.scalar() or 0
                    except Exception as e:
                        logger.error(f"‚ùå Error getting INTRO_SHOWN for {date_str}: {e}")
                        stage_counts[OnboardingStage.INTRO_SHOWN] = 0
                    
                    # 2. WAIT_PAYMENT: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –≤ —Å—Ç–∞–¥–∏–∏ –æ–∂–∏–¥–∞–Ω–∏—è –æ–ø–ª–∞—Ç—ã
                    try:
                        wait_result = await session.execute(
                            select(func.count(User.id))
                            .where(
                                and_(
                                    User.created_at >= date_start,
                                    User.created_at < date_end,
                                    User.onboarding_stage == OnboardingStage.WAIT_PAYMENT
                                )
                            )
                        )
                        stage_counts[OnboardingStage.WAIT_PAYMENT] = wait_result.scalar() or 0
                    except Exception as e:
                        logger.error(f"‚ùå Error getting WAIT_PAYMENT for {date_str}: {e}")
                        stage_counts[OnboardingStage.WAIT_PAYMENT] = 0
                    
                    # 3. PAYMENT_OK: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å payment_completed=True –ò —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–µ–π –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å
                    try:
                        same_day_payment_result = await session.execute(
                            select(func.count(User.id))
                            .where(
                                and_(
                                    User.created_at >= date_start,
                                    User.created_at < date_end,
                                    User.payment_completed == True
                                )
                            )
                        )
                        same_day_payments = same_day_payment_result.scalar() or 0
                        stage_counts[OnboardingStage.PAYMENT_OK] = same_day_payments
                        
                    except Exception as e:
                        logger.error(f"‚ùå Error getting PAYMENT_OK for {date_str}: {e}")
                        stage_counts[OnboardingStage.PAYMENT_OK] = 0
                    
                    # 4. DAILY_PAYMENTS: –í–°–ï –ø–ª–∞—Ç–µ–∂–∏ –∑–∞ –¥–µ–Ω—å
                    try:
                        # Robokassa –ø–ª–∞—Ç–µ–∂–∏ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                        robokassa_count = 0
                        try:
                            from app.database.models import Payment
                            robokassa_payments = await session.execute(
                                select(func.count(Payment.id))
                                .where(
                                    and_(
                                        func.date(Payment.created_at) == date_obj.date(),
                                        Payment.status == "paid"
                                    )
                                )
                            )
                            robokassa_count = robokassa_payments.scalar() or 0
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Could not get Robokassa payments for {date_str}: {e}")
                        
                        # GetCourse –ø–ª–∞—Ç–µ–∂–∏ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                        sales_count = 0
                        try:
                            from app.database.models import Sale
                            sales_payments = await session.execute(
                                select(func.count(Sale.id))
                                .where(func.date(Sale.created_at) == date_obj.date())
                            )
                            sales_count = sales_payments.scalar() or 0
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Could not get GetCourse sales for {date_str}: {e}")
                        
                        # –ò—Ç–æ–≥–æ–≤—ã–π –ø–æ–¥—Å—á–µ—Ç
                        daily_payments_count = robokassa_count + sales_count
                        stage_counts["DAILY_PAYMENTS"] = daily_payments_count
                        
                    except Exception as e:
                        logger.error(f"‚ùå Error getting DAILY_PAYMENTS for {date_str}: {e}")
                        stage_counts["DAILY_PAYMENTS"] = 0
                    
                    result[date_str] = stage_counts
                    
                except Exception as date_error:
                    logger.error(f"‚ùå Error processing date {date_str}: {date_error}")
                    result[date_str] = {
                        OnboardingStage.NEW_USER: 0,
                        OnboardingStage.INTRO_SHOWN: 0,
                        OnboardingStage.WAIT_PAYMENT: 0,
                        OnboardingStage.PAYMENT_OK: 0,
                        "DAILY_PAYMENTS": 0
                    }
                    continue
        
        logger.info(f"‚úÖ Successfully processed {len(result)} dates for stages")
        return result
    
    async def get_existing_data(self) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"""
        existing_data = {}
        try:
            all_values = self.worksheet.get_all_values()
            if len(all_values) > 1:
                for row in all_values[1:]:
                    if len(row) >= 3 and row[0]:
                        existing_data[row[0]] = {
                            'time': row[1] if len(row) > 1 else '',
                            'data': row[2:] if len(row) > 2 else [],
                            'row_data': row
                        }
                logger.info(f"üìã Found {len(existing_data)} existing rows in sheet")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not read existing data: {e}")
            existing_data = {}
        
        return existing_data
    
    async def safe_update_sheet(self, all_rows: List[List[str]]) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        try:
            logger.info(f"üìÑ Starting safe update of {len(all_rows)} rows")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
            await self.create_backup()
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.worksheet.clear()
            time.sleep(1)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headers = ["–î–∞—Ç–∞", "–í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"] + [STAGE_NAMES[stage] for stage in REQUIRED_STAGES]
            self.worksheet.update(range_name='A1:G1', values=[headers])
            time.sleep(1)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ü–∏—è–º–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            batch_size = 50
            total_batches = (len(all_rows) + batch_size - 1) // batch_size
            
            for i in range(0, len(all_rows), batch_size):
                batch = all_rows[i:i + batch_size]
                batch_num = i // batch_size + 1
                
                try:
                    self.worksheet.append_rows(batch)
                    logger.info(f"üìÑ Batch {batch_num}/{total_batches}: {len(batch)} rows added")
                    time.sleep(1)
                    
                except Exception as batch_error:
                    logger.error(f"‚ùå Error in batch {batch_num}: {batch_error}")
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –±—ç–∫–∞–ø–∞
                    logger.info("üîÑ Attempting to restore from backup...")
                    if await self.restore_from_backup():
                        logger.info("‚úÖ Data restored from backup")
                        return False
                    else:
                        logger.error("‚ùå Failed to restore from backup!")
                        return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–ª–∏—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
            verification_data = self.worksheet.get_all_values()
            if len(verification_data) != len(all_rows) + 1:
                logger.error(f"‚ùå Data verification failed! Expected {len(all_rows) + 1}, got {len(verification_data)}")
                if await self.restore_from_backup():
                    logger.info("‚úÖ Data restored from backup after verification failure")
                return False
            
            logger.info(f"‚úÖ Safe update completed successfully: {len(all_rows)} rows written")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Critical error in safe_update_sheet: {e}")
            logger.info("üîÑ Attempting emergency restore...")
            if await self.restore_from_backup():
                logger.info("‚úÖ Emergency restore successful")
            else:
                logger.error("‚ùå Emergency restore failed!")
            return False
    
    async def update_today_time_only(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        try:
            current_time = datetime.now(MOSCOW_TZ).strftime('%H:%M –ú–°–ö')
            today_formatted = datetime.now(MOSCOW_TZ).strftime('%d.%m.%Y')
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            existing_data = await self.get_existing_data()
            
            if not existing_data:
                logger.info("üìÑ No existing data found")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–µ–≥–æ–¥–Ω—è—à–Ω—è—è –∑–∞–ø–∏—Å—å
            if today_formatted not in existing_data:
                logger.info(f"üìÑ Today's date ({today_formatted}) not found in existing data")
                return False
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏
            all_rows = []
            for date_str in sorted(existing_data.keys(), key=lambda x: datetime.strptime(x, '%d.%m.%Y'), reverse=True):
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—Ä–µ–º—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è, –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - –ø—É—Å—Ç–æ–µ
                if date_str == today_formatted:
                    time_to_use = current_time
                    logger.info(f"üïê Updated time for today ({date_str}): {current_time}")
                else:
                    time_to_use = ""  # –ü—É—Å—Ç–æ–µ –≤—Ä–µ–º—è –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –¥–∞—Ç
                
                row_data = [date_str, time_to_use] + existing_data[date_str]['data']
                all_rows.append(row_data)
            
            return await self.safe_update_sheet(all_rows)
            
        except Exception as e:
            logger.error(f"‚ùå Error in update_today_time_only: {e}")
            return False
    
    async def incremental_update(self):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ - —Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ"""
        try:
            current_time = datetime.now(MOSCOW_TZ).strftime('%H:%M –ú–°–ö')
            today_formatted = datetime.now(MOSCOW_TZ).strftime('%d.%m.%Y')
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            existing_data = await self.get_existing_data()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–æ–≥–æ–≤
            users_by_date = await self.get_users_from_logs_by_date(None)
            
            if not users_by_date:
                logger.info("üìÑ No data found in logs")
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ª–æ–≥–∞—Ö –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å —Å–µ–≥–æ–¥–Ω—è—à–Ω—è—è –∑–∞–ø–∏—Å—å - –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                return await self.update_today_time_only()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –¥–∞—Ç—ã –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å
            all_dates_from_logs = set(users_by_date.keys())
            existing_dates = set(existing_data.keys())
            
            # –î–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å
            dates_to_process = []
            
            for date_str in all_dates_from_logs:
                formatted_date = datetime.strptime(date_str, '%Y-%m-%d').strftime('%d.%m.%Y')
                
                if formatted_date not in existing_dates:
                    dates_to_process.append(date_str)
                    logger.info(f"‚ûï Will add new date: {formatted_date}")
                elif formatted_date == today_formatted:
                    dates_to_process.append(date_str)
                    logger.info(f"üîÑ Will update today's data: {formatted_date}")
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, –Ω–æ –µ—Å—Ç—å —Å–µ–≥–æ–¥–Ω—è—à–Ω—è—è –∑–∞–ø–∏—Å—å - –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
            if not dates_to_process:
                logger.info("üìÑ No new data to process")
                return await self.update_today_time_only()
            
            logger.info(f"üìä Processing {len(dates_to_process)} dates")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ç–∞–¥–∏—è–º —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω—É–∂–Ω—ã—Ö –¥–∞—Ç
            stage_data = await self.get_users_by_stages_for_dates(dates_to_process)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            for date_str in dates_to_process:
                formatted_date = datetime.strptime(date_str, '%Y-%m-%d').strftime('%d.%m.%Y')
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                new_users_count = len(users_by_date.get(date_str, set()))
                date_stage_data = stage_data.get(date_str, {})
                
                row_data = [str(new_users_count)]
                
                for stage in REQUIRED_STAGES[1:]:
                    count = date_stage_data.get(stage, 0)
                    row_data.append(str(count))
                
                # –í—Ä–µ–º—è –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è
                time_for_this_date = current_time if formatted_date == today_formatted else existing_data.get(formatted_date, {}).get('time', '')
                
                existing_data[formatted_date] = {
                    'time': time_for_this_date,
                    'data': row_data
                }
                
                if formatted_date == today_formatted:
                    logger.info(f"üïê Updated time for today ({formatted_date}): {current_time}")
                else:
                    logger.info(f"üìã Updated data for {formatted_date} (time unchanged)")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏

            all_rows = []
            for date_str in sorted(existing_data.keys(), key=lambda x: datetime.strptime(x, '%d.%m.%Y'), reverse=True):
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—Ä–µ–º—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è
                if date_str == today_formatted:
                    time_to_use = existing_data[date_str]['time']
                else:
                    time_to_use = ""  # –ü—É—Å—Ç–æ–µ –≤—Ä–µ–º—è –¥–ª—è –≤—Å–µ—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞—Ç
                
                row_data = [date_str, time_to_use] + existing_data[date_str]['data']
                all_rows.append(row_data)
            
            return await self.safe_update_sheet(all_rows)
            
        except Exception as e:
            logger.error(f"‚ùå Error in incremental_update: {e}", exc_info=True)
            return False
    
    async def full_update(self):
        """–ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–æ–≥–æ–≤
            users_by_date = await self.get_users_from_logs_by_date(None)
            
            if not users_by_date:
                logger.info("üìÑ No data found in logs")
                return True
            
            all_dates_from_logs = list(users_by_date.keys())
            logger.info(f"üìä Found {len(all_dates_from_logs)} dates in logs")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ç–∞–¥–∏—è–º
            stage_data = await self.get_users_by_stages_for_dates(all_dates_from_logs)
            
            if not stage_data:
                logger.error("‚ùå No stage data received")
                return False
            
            current_time = datetime.now(MOSCOW_TZ).strftime('%H:%M –ú–°–ö')
            today_formatted = datetime.now(MOSCOW_TZ).strftime('%d.%m.%Y')
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏
            all_rows = []
            
            for date_str in sorted(all_dates_from_logs, reverse=True):
                try:
                    formatted_date = datetime.strptime(date_str, '%Y-%m-%d').strftime('%d.%m.%Y')
                    
                    # –í—Ä–µ–º—è –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è
                    time_column = current_time if formatted_date == today_formatted else ""
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                    new_users_count = len(users_by_date.get(date_str, set()))
                    date_stage_data = stage_data.get(date_str, {})
                    
                    row_data = [
                        formatted_date,
                        time_column,
                        str(new_users_count)
                    ]
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–∞–¥–∏–∏
                    for stage in REQUIRED_STAGES[1:]:
                        count = date_stage_data.get(stage, 0)
                        row_data.append(str(count))
                    
                    all_rows.append(row_data)
                    
                    if formatted_date == today_formatted:
                        logger.info(f"üïê Today's row ({formatted_date}): time={time_column}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error preparing row for {date_str}: {e}")
                    continue
            
            return await self.safe_update_sheet(all_rows)
            
        except Exception as e:
            logger.error(f"‚ùå Error in full_update: {e}", exc_info=True)
            return False
        
    async def run(self, mode='incremental'):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞
        
        Args:
            mode (str): –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:
                - 'full': –ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
                - 'incremental': –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–µ)
                - 'today_time': –û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –∑–∞–ø–∏—Å–∏
        """
        logger.info(f"üöÄ Starting FINAL conversion analytics v4.7 in '{mode}' mode...")
        
        if not await self.init():
            logger.error("‚ùå Failed to initialize")
            return False
        
        try:
            success = False
            
            if mode == 'full':
                success = await self.full_update()
                
            elif mode == 'incremental':
                success = await self.incremental_update()
                
            elif mode == 'today_time':
                success = await self.update_today_time_only()
                
            else:
                logger.error(f"‚ùå Unknown mode: {mode}")
                return False
            
            if success:
                current_time = datetime.now(MOSCOW_TZ).strftime('%H:%M –ú–°–ö')
                logger.info("=" * 60)
                logger.info(f"üìä FINAL CONVERSION ANALYTICS v4.7 COMPLETE ({mode.upper()} mode)")
                logger.info(f"  ‚è∞ Last update time: {current_time}")
                logger.info("  ‚úÖ PAYMENT_OK: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å payment_completed=True –ò —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–µ–π –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å") 
                logger.info("  ‚úÖ DAILY_PAYMENTS: –í–°–ï –ø–ª–∞—Ç–µ–∂–∏ –∑–∞ –¥–µ–Ω—å (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –¥–∞—Ç—ã —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏)")
                logger.info("  ‚úÖ –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è")
                logger.info("  ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º")
                logger.info("=" * 60)
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Critical error in run: {e}", exc_info=True)
            
            # –ü–æ–ø—ã—Ç–∫–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            logger.info("üö® Attempting emergency data recovery...")
            if await self.restore_from_backup():
                logger.info("‚úÖ Emergency recovery successful")
            else:
                logger.error("‚ùå Emergency recovery failed!")
            
            return False


async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–µ–∂–∏–º–æ–≤ —Ä–∞–±–æ—Ç—ã"""
    parser = argparse.ArgumentParser(description='Conversion Analytics Script v4.7 - Time Update Only for Today')
    parser.add_argument('--mode', 
                       choices=['full', 'incremental', 'today_time'], 
                       default='incremental',
                       help='Update mode (default: incremental)')
    parser.add_argument('--backup-only', 
                       action='store_true',
                       help='Only create backup without updating')
    parser.add_argument('--restore', 
                       action='store_true',
                       help='Restore data from backup')
    
    args = parser.parse_args()
    
    analytics = ConversionAnalyticsFinal()
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã
    if args.backup_only:
        logger.info("üíæ Backup-only mode")
        if await analytics.init():
            await analytics.create_backup()
            logger.info("‚úÖ Backup completed")
        return
    
    if args.restore:
        logger.info("üîÑ Restore mode")
        if await analytics.init():
            success = await analytics.restore_from_backup()
            if success:
                logger.info("‚úÖ Restore completed successfully")
                sys.exit(0)
            else:
                logger.error("‚ùå Restore failed")
                sys.exit(1)
        return
    
    # –û–±—ã—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞
    success = await analytics.run(mode=args.mode)
    
    if success:
        logger.info(f"‚úÖ Final analytics v4.7 completed successfully in {args.mode} mode")
        sys.exit(0)
    else:
        logger.error(f"‚ùå Final analytics failed in {args.mode} mode")
        sys.exit(1)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è Script interrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}", exc_info=True)
        sys.exit(1)